{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 4, 'NUM_BF': 3, 'NUM_DF': 13, 'FEAT_DIM': 32, 'NUM_WORKERS': 32, 'EPOCHS_NUM': 2010, 'LR': 1e-05, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0, 'LR_DISC': 1e-06, 'WEIGHT_DISC': 10.0, 'WEIGHT_TV': 0, 'WEIGHT_FORWARD': 0, 'WEIGHT_STAIN': 1, 'TRAIN_SIZE': 768, 'TEST_SIZE': 8, 'VALID_SIZE': 768, 'MODE': 'train', 'SAVE_SUBITER': 20, 'TRAIN_MODE': 'ENTIRE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkyungchul-eee\u001b[0m (\u001b[33moisl\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.22.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data3/KC/virtual_staining/wandb/wandb/run-20251015_091457-w3l6lz8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oisl/ENTIRE/runs/w3l6lz8r' target=\"_blank\">rack_20251015_091455</a></strong> to <a href='https://wandb.ai/oisl/ENTIRE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oisl/ENTIRE' target=\"_blank\">https://wandb.ai/oisl/ENTIRE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oisl/ENTIRE/runs/w3l6lz8r' target=\"_blank\">https://wandb.ai/oisl/ENTIRE/runs/w3l6lz8r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kcl724/.local/lib/python3.11/site-packages/torch/nn/functional.py:3782: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/usr/lib/python3.11/shutil.py\", line 738, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.11/shutil.py\", line 736, in rmtree\n",
      "    os.rmdir(path, dir_fd=dir_fd)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-s_bj5jpu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 0. time: 121.49s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kcl724/.local/lib/python3.11/site-packages/torch/nn/functional.py:3782: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 1. time: 115.36s.\n",
      "Train :: epoch: 2. time: 115.71s.\n",
      "Train :: epoch: 3. time: 112.99s.\n",
      "Train :: epoch: 4. time: 113.32s.\n",
      "Train :: epoch: 5. time: 118.35s.\n",
      "Train :: epoch: 6. time: 119.19s.\n",
      "Train :: epoch: 7. time: 118.02s.\n",
      "Train :: epoch: 8. time: 120.05s.\n",
      "Train :: epoch: 9. time: 117.58s.\n",
      "Train :: epoch: 10. time: 121.61s.\n",
      "Train :: epoch: 11. time: 119.2s.\n",
      "Train :: epoch: 12. time: 121.65s.\n",
      "Train :: epoch: 13. time: 122.42s.\n",
      "Train :: epoch: 14. time: 122.52s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 15. time: 120.32s.\n",
      "Train :: epoch: 16. time: 122.02s.\n",
      "Train :: epoch: 17. time: 117.38s.\n",
      "Train :: epoch: 18. time: 121.3s.\n",
      "Train :: epoch: 19. time: 126.3s.\n",
      "Train :: epoch: 20. time: 126.52s.\n",
      "Train :: epoch: 21. time: 123.4s.\n",
      "Train :: epoch: 22. time: 126.42s.\n",
      "Train :: epoch: 23. time: 126.22s.\n",
      "Train :: epoch: 24. time: 124.16s.\n",
      "Train :: epoch: 25. time: 128.54s.\n",
      "Train :: epoch: 26. time: 127.43s.\n",
      "Train :: epoch: 27. time: 126.56s.\n",
      "Train :: epoch: 28. time: 127.09s.\n",
      "Train :: epoch: 29. time: 127.07s.\n",
      "Train :: epoch: 30. time: 131.74s.\n",
      "Train :: epoch: 31. time: 128.07s.\n",
      "Train :: epoch: 32. time: 128.09s.\n",
      "Train :: epoch: 33. time: 131.87s.\n",
      "Train :: epoch: 34. time: 128.89s.\n",
      "Train :: epoch: 35. time: 124.68s.\n",
      "Train :: epoch: 36. time: 133.48s.\n",
      "Train :: epoch: 37. time: 130.95s.\n",
      "Train :: epoch: 38. time: 129.61s.\n",
      "Train :: epoch: 39. time: 128.46s.\n",
      "Train :: epoch: 40. time: 133.78s.\n",
      "Train :: epoch: 41. time: 133.72s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (10.9MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 42. time: 132.61s.\n",
      "Train :: epoch: 43. time: 134.91s.\n",
      "Train :: epoch: 44. time: 134.43s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (11.4MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 45. time: 134.16s.\n",
      "Train :: epoch: 46. time: 135.38s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (12.3MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 47. time: 128.64s.\n",
      "Train :: epoch: 48. time: 134.88s.\n",
      "Train :: epoch: 49. time: 135.42s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (12.7MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 50. time: 133.87s.\n",
      "Train :: epoch: 51. time: 132.06s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (13.2MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 52. time: 135.25s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (13.6MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 53. time: 140.65s.\n",
      "Train :: epoch: 54. time: 139.56s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (14.1MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 55. time: 139.9s.\n",
      "Train :: epoch: 56. time: 133.37s.\n",
      "Train :: epoch: 57. time: 144.0s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (15.0MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 58. time: 141.63s.\n",
      "Train :: epoch: 59. time: 139.37s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (15.5MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 60. time: 143.06s.\n",
      "Train :: epoch: 61. time: 141.59s.\n",
      "Train :: epoch: 62. time: 138.91s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (16.4MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 63. time: 146.09s.\n",
      "Train :: epoch: 64. time: 141.66s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (16.8MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 65. time: 143.21s.\n",
      "Train :: epoch: 66. time: 143.34s.\n",
      "Train :: epoch: 67. time: 135.66s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (17.7MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 68. time: 143.73s.\n",
      "Train :: epoch: 69. time: 146.59s.\n",
      "Train :: epoch: 70. time: 145.4s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (18.2MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 71. time: 145.42s.\n",
      "Train :: epoch: 72. time: 143.67s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (19.1MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 73. time: 140.63s.\n",
      "Train :: epoch: 74. time: 141.86s.\n",
      "Train :: epoch: 75. time: 142.4s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (19.6MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 76. time: 138.9s.\n",
      "Train :: epoch: 77. time: 141.11s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (20.0MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 78. time: 139.67s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (20.5MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 79. time: 141.42s.\n",
      "Train :: epoch: 80. time: 143.15s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (20.9MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 81. time: 142.02s.\n",
      "Train :: epoch: 82. time: 141.97s.\n",
      "Train :: epoch: 83. time: 142.47s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (21.8MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 84. time: 146.68s.\n",
      "Train :: epoch: 85. time: 145.72s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (22.3MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 86. time: 145.75s.\n",
      "Train :: epoch: 87. time: 142.66s.\n",
      "Train :: epoch: 88. time: 147.95s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (23.2MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 89. time: 143.61s.\n",
      "Train :: epoch: 90. time: 147.92s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (23.6MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 91. time: 147.47s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (23.7MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 92. time: 147.15s.\n",
      "Train :: epoch: 93. time: 147.41s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (24.6MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :: epoch: 94. time: 148.61s.\n",
      "Train :: epoch: 95. time: 146.0s.\n",
      "Train :: epoch: 96. time: 147.21s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Metric data exceeds maximum size of 10.4MB (25.0MB)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feaa1ba94e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kcl724/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kcl724/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7feaa1ba94e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kcl724/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kcl724/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import wandb\n",
    "import models\n",
    "\n",
    "from FPM_recon_dataset_RED import FPM_recon_dataset_RED\n",
    "from FPM_dataset_RED import FPM_dataset_RED\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import imageio\n",
    "import visualizer\n",
    "from PIL import Image\n",
    "import io\n",
    "from utils import *\n",
    "\n",
    "# Notation for individual wandb log name\n",
    "NOTES = 'train'\n",
    "\n",
    "# Define network hyperparameters:\n",
    "HPARAMS = {\n",
    "    'BATCH_SIZE': 4,\n",
    "    'NUM_BF': 3,\n",
    "    'NUM_DF': 13,\n",
    "    'FEAT_DIM': 32,  ##32\n",
    "    'NUM_WORKERS': 32,\n",
    "    'EPOCHS_NUM': 2010,\n",
    "    'LR': 0.00001,\n",
    "    'MOMENTUM': 0.9,\n",
    "    'WEIGHT_DECAY' : 0,\n",
    "    'LR_DISC' : 0.000001,\n",
    "    'WEIGHT_DISC' : 1e+1, #1e-1 1e+3 1e+1\n",
    "    'WEIGHT_TV':0,\n",
    "    'WEIGHT_FORWARD':0,#1e-2\n",
    "    'WEIGHT_STAIN' : 1,\n",
    "    'TRAIN_SIZE':768,#384\n",
    "    'TEST_SIZE':8,\n",
    "    'VALID_SIZE':768,#551\n",
    "    'MODE' : 'train', #'inference' train\n",
    "    'SAVE_SUBITER':20,\n",
    "    'TRAIN_MODE':'ENTIRE' # 'RECON', 'STAIN', 'ENTIRE'\n",
    "}\n",
    "\n",
    "\n",
    "## end2end\n",
    "LR_LED = HPARAMS['LR'] * 1e+3\n",
    "LR_HEAD = HPARAMS['LR'] * 1e+0\n",
    "LR_BODY = HPARAMS['LR'] * 1e+0\n",
    "LR_TAIL = HPARAMS['LR'] * 1e+0\n",
    "LR_CONTRASTIVE = HPARAMS['LR'] * 0\n",
    "\n",
    "\n",
    "print(HPARAMS)\n",
    "## stain\n",
    "## wo discriminator\n",
    "\n",
    "name_weight_disc = 'disc_valid_20230731_102450_00400'\n",
    "\n",
    "## forward model\n",
    "#slide 32\n",
    "# name_weight_stain='stain_20240523_053356_00500'\n",
    "# name_weight_recon='recon_20240523_053356_00100' \n",
    "\n",
    "#slide 34\n",
    "# name_weight_stain='stain_20240524_165751_00500'\n",
    "# name_weight_recon='recon_20240524_165751_00100' ## w/o/ forward\n",
    "\n",
    "#slide 15\n",
    "# name_weight_stain='recon_20240529_004020_00300'\n",
    "# name_weight_recon='stain_20240529_004020_00300' ## w/o/ forward\n",
    "\n",
    "\n",
    "##reference\n",
    "# name_weight_stain='stain_20240529_004020_00300'\n",
    "# name_weight_recon='recon_20240529_004020_00300' ## reference\n",
    "\n",
    "\n",
    "#bladder\n",
    "# name_weight_stain='stain_20240607_130234_00600'\n",
    "# name_weight_recon='recon_20240607_130234_00600' ## w/o/ forward\n",
    "\n",
    "#stomach\n",
    "# name_weight_stain='stain_20240605_224330_00600'\n",
    "# name_weight_recon='recon_20240605_224330_00600' ## w/o/ forward\n",
    "\n",
    "#stomach/bladder\n",
    "# name_weight_stain='stain_20240619_050050_00600'\n",
    "# name_weight_recon='recon_20240619_050050_00600' ## w/o/ forward\n",
    "\n",
    "\n",
    "\n",
    "## LED\n",
    "# ## led 32\n",
    "# name_weight_stain='stain_20240619_050050_00600'\n",
    "# name_weight_recon='recon_20240627_020315_00400' ## w/o/ forward\n",
    "\n",
    "# ## led 16\n",
    "# name_weight_stain='stain_20240605_224330_00600'\n",
    "# name_weight_recon='recon_20240605_224330_00600' ## w/o/ forward\n",
    "\n",
    "# ## led 12\n",
    "# name_weight_stain='stain_20240626_145525_00400'\n",
    "# name_weight_recon='recon_20240626_145525_00400' ## w/o/ forward\n",
    "\n",
    "# ## led 8\n",
    "# name_weight_stain='stain_20240626_004723_00400'\n",
    "# name_weight_recon='recon_20240626_004723_00400' ## w/o/ forward\n",
    "\n",
    "## led 0\n",
    "# name_weight_stain='stain_20240625_101111_00400'\n",
    "# name_weight_recon='recon_20240625_101111_00400' ## w/o/ forward\n",
    "\n",
    "## single layer\n",
    "# name_weight_stain='stain_20240629_151745_00500'\n",
    "# name_weight_recon='recon_20240724_155130_00800' \n",
    "\n",
    "\n",
    "#stomach\n",
    "name_weight_stain = 'stain_20241113_114121_00400'\n",
    "name_weight_recon = 'recon_20241113_114121_00400' \n",
    "\n",
    "\n",
    "#bladder\n",
    "# name_weight_stain = 'stain_20250218_140147_00600'\n",
    "# name_weight_recon = 'recon_20250218_140147_00600' \n",
    "\n",
    "#bladder new\n",
    "# name_weight_stain = 'stain_20250220_110111_00600'\n",
    "# name_weight_recon = 'recon_20250220_110111_00600' ## w/o/ forward\n",
    "\n",
    "\n",
    "TPARAMS = {}\n",
    "IMAGE_SHAPE = (193, 200, 200)\n",
    "IMAGE_SHAPE_INTER = (1, 600, 600)\n",
    "\n",
    "# for model save, use time for data name variation\n",
    "START_DATE = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "  \n",
    "\n",
    "# baseDir=\"/home/kcl724/data/data3/KC/virtual_staining/\"\n",
    "baseDir = \"/mnt/data3/KC/virtual_staining/\"\n",
    "images_raw=[]\n",
    "images_raw_valid=[]\n",
    "images_raw_test=[]\n",
    "images_raw.append('/mnt/data3/FPM_com/tissue NIR dataset/02.sto_S_15-71892_sec1/R/Dataset/')\n",
    "images_raw.append('/mnt/data3/FPM_com/tissue NIR dataset/06.sto_S_10-805_sec1/R/Dataset/')\n",
    "images_raw.append('/mnt/data3/FPM_com/tissue NIR dataset/13.sto_S_15-711892_sec3/R/Dataset/')\n",
    "images_raw.append('/mnt/data3/FPM_com/tissue NIR dataset/22.sto_S_A3 18-37852_sec1/R/Dataset/')\n",
    "\n",
    "# images_raw.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/15.bladder_S_A4_23-36533_sec1/R/Dataset/')\n",
    "# images_raw.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/14.bladder_S_A1_23-36533_sec1/R/Dataset/')\n",
    "# images_raw.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/44.bla_F3_A1_23-36533_sec2z/R/Dataset/')\n",
    "# images_raw.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/34.bla_U_A4 23-36533_sec2/R/Dataset/')\n",
    "\n",
    "\n",
    "\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/34.bla_U_A4 23-36533_sec2/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/44.bla_F3_A1_23-36533_sec2/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/15.bladder_S_A1_23-36533_sec1/R/Dataset/')\n",
    "\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/38.bla_U_A12_23-35177_sec1/R/Dataset/')\n",
    "\n",
    "images_raw_valid.append('/mnt/data3/FPM_com/tissue NIR dataset/02.sto_S_15-71892_sec1/R/Dataset/')\n",
    "images_raw_valid.append('/mnt/data3/FPM_com/tissue NIR dataset/22.sto_S_A3 18-37852_sec1/R/Dataset/')\n",
    "images_raw_valid.append('/mnt/data3/FPM_com/tissue NIR dataset/32.sto_S2F(U)_A3 18-37852_sec1(pair22)/R/Dataset/')\n",
    "images_raw_valid.append('/mnt/data3/FPM_com/tissue NIR dataset/40.sto_F3_A3_18-37852_sec2/R/Dataset/')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/33.sto_U_A3 16-68231_sec1/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/35.sto_U_A3_16-68231_sec1/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/36.sto_U_A3_16-68231_sec2/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/37.sto_U_A3_16-68231_sec3/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/39.sto_F1_A3_16-68731_sec1/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/40.sto_F3_A3_18-37852_sec2/R/Dataset/')\n",
    "\n",
    "\n",
    "\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/34.bla_U_A4 23-36533_sec2/R/Dataset/')\n",
    "# images_raw_valid.append('/home/kcl724/data/data3/FPM_com/tissue NIR dataset/38.bla_U_A12_23-35177_sec1/R/Dataset/')\n",
    "\n",
    "\n",
    "if HPARAMS['MODE'] =='train':\n",
    "    # wandb.login()\n",
    "    wandb.init(project=HPARAMS['TRAIN_MODE'],\n",
    "               config=HPARAMS,\n",
    "               name='rack_'+START_DATE,\n",
    "               dir = baseDir+'wandb',\n",
    "               # mode='disabled',\n",
    "               notes=NOTES)\n",
    "\n",
    "if HPARAMS['MODE'] =='inference':\n",
    "    currdate=datetime.datetime.today().strftime(\"%Y%m%d%H%M%S\")\n",
    "    save_img_dir=baseDir+'imgs/'+currdate+'_'+name_weight_stain+'_'+name_weight_disc+'/'    \n",
    "    \n",
    "\n",
    "save_weight_dir=baseDir+\"weights/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_imgs(parameters,saveDir):\n",
    "\n",
    "    result = {} \n",
    "    \n",
    "    maxVal_stain=torch.tensor(1)\n",
    "    maxVal_phase=torch.tensor(1)\n",
    "    minVal_phase=torch.tensor(0)\n",
    "\n",
    "    mode = 'stain'\n",
    "    os.makedirs(saveDir+'stain/')\n",
    "    os.makedirs(saveDir+'phase/')    \n",
    "    os.makedirs(saveDir+'mat/')\n",
    "    print('start save')\n",
    "    \n",
    "    \n",
    "    leds=led_visualize(parameters)\n",
    "    plt.figure()\n",
    "    plt.imshow(leds)\n",
    "    plt.show()\n",
    "    psnr_array = []\n",
    "    ssim_array = []\n",
    "    mse_array = []\n",
    "    if mode == 'entire':\n",
    "        parameters['model_stain'].eval()\n",
    "        parameters['model_recon'].eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for i, (data_unstained, target_unstained,cropR_unstained) in enumerate(parameters['validset_loader']):\n",
    "                data_unstained,target_unstained = data_unstained.to(DEVICE),target_unstained.to(DEVICE)\n",
    "                output_recon = parameters['model_recon'](data_unstained)\n",
    "                output_stain_unstained,f1 = parameters['model_stain'](output_recon[:,0,:,:].view(-1,1,600,600))\n",
    "                # unstain tissue processing                    \n",
    "                result_phase_unstained=target_unstained[:,3,:,:].view(-1,1,600,600).squeeze(0).squeeze(0)    \n",
    "                result_stain_unstained=output_stain_unstained.view(-1,3,600,600).squeeze(0)\n",
    "                # result_phase_unstained=minmax_norm_number(result_phase_unstained,maxVal_phase,minVal_phase).detach().cpu().numpy()\n",
    "                result_phase_unstained=minmax_norm_number(result_phase_unstained,torch.max(result_phase_unstained),torch.min(result_phase_unstained)).detach().cpu().numpy()\n",
    "                result_stain_unstained=minmax_norm_number(result_stain_unstained,maxVal_stain,0).detach().cpu().numpy()\n",
    "                result_stain_unstained=alt_axis(result_stain_unstained)\n",
    "                \n",
    "        \n",
    "                # imageio.imwrite(saveDir+'stain/'+ 'stain_unstained_{0:03d}'.format(i)+'.png',(result_stain_unstained*255).astype(np.uint8))\n",
    "                imageio.imwrite(saveDir+'phase/'+ 'phase_unstained_{0:03d}'.format(i)+'.jpg',(result_phase_unstained*255).astype(np.uint8))\n",
    "                \n",
    "    \n",
    "    elif mode =='stain':\n",
    "        # parameters['model_stain'].eval()\n",
    "        parameters['model_recon'].eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (data_unstained, target_unstained,cropR_unstained) in enumerate(parameters['validset_loader']):\n",
    "                data_unstained,target_unstained = data_unstained.to(DEVICE),target_unstained.to(DEVICE)\n",
    "                output_stain_unstained = parameters['model_recon'](data_unstained)\n",
    "                # unstain tissue processing                    \n",
    "                result_phase_unstained=target_unstained[:,3,:,:].view(-1,1,600,600).squeeze(0).squeeze(0)    \n",
    "                result_stain_unstained=output_stain_unstained.view(-1,3,600,600).squeeze(0)\n",
    "                result_phase_unstained=minmax_norm_number(result_phase_unstained,maxVal_phase,minVal_phase).detach().cpu().numpy()\n",
    "                result_stain_unstained=minmax_norm_number(result_stain_unstained,maxVal_stain,0).detach().cpu().numpy()\n",
    "                result_stain_unstained=alt_axis(result_stain_unstained)\n",
    "\n",
    "\n",
    "                imageio.imwrite(saveDir+'stain/'+ 'stain_unstained_{0:03d}'.format(i)+'.png',(result_stain_unstained*256).astype(np.uint8))\n",
    "                imageio.imwrite(saveDir+'phase/'+ 'phase_unstained_{0:03d}'.format(i)+'.png',(result_phase_unstained*256).astype(np.uint8))\n",
    "\n",
    "                scipy.io.savemat(saveDir+'mat/'+'result_{0:03d}'.format(i)+'.mat',{\"stain_unstained\":result_stain_unstained,\"phase_unstained\":result_phase_unstained})\n",
    "    print('end save')\n",
    "    print(np.mean(psnr_array))\n",
    "    print(np.mean(ssim_array))\n",
    "    print(np.mean(mse_array))\n",
    "    \n",
    "    \n",
    "\n",
    "class LossFunction():\n",
    "    \"\"\"Loss function class for multiple loss function.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.criterion_mse = torch.nn.MSELoss().to(DEVICE)\n",
    "        self.criterion_l1 = torch.nn.L1Loss().to(DEVICE)\n",
    "        self.CrossEntropyLoss=torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, output, label, mode, epoch=0):\n",
    "        if mode=='l1':\n",
    "            l1_loss = self.criterion_l1(output, label)\n",
    "            loss = l1_loss\n",
    "        elif mode=='mse':\n",
    "            mse_loss = self.criterion_mse(output, label)\n",
    "            loss = mse_loss\n",
    "        elif mode=='BCE':\n",
    "            BCELoss = self.CrossEntropyLoss(output, label)\n",
    "            loss = BCELoss\n",
    "        return loss\n",
    "\n",
    "def data_sampler(dataset,train_size,test_size,mode='train'):\n",
    "    \"\"\"data sampling function\n",
    "    Note:\n",
    "        \n",
    "    Args:\n",
    "        dataset\n",
    "        train_size\n",
    "        test_size\n",
    "        \n",
    "    Returns:\n",
    "        train_loader\n",
    "        test_loader\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    if mode =='train':\n",
    "         \n",
    "        np.random.shuffle(indices)\n",
    "        train_indices, test_indices = indices[:train_size], indices[train_size:train_size+test_size]\n",
    "        # train_sampler=train_indices\n",
    "        \n",
    "        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "        test_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=HPARAMS['BATCH_SIZE'],\n",
    "                                               num_workers=HPARAMS['NUM_WORKERS'],\n",
    "                                               sampler=train_sampler,\n",
    "                                               # drop_last=True, shuffle=False\n",
    "                                                  )\n",
    "        test_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                  batch_size=HPARAMS['BATCH_SIZE'],\n",
    "                                                  num_workers=HPARAMS['NUM_WORKERS'],\n",
    "                                                  sampler=test_sampler,\n",
    "                                                  # shuffle=False\n",
    "                                                  )\n",
    "\n",
    "    elif mode =='inference':\n",
    "        train_indices=indices\n",
    "        train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_size=HPARAMS['BATCH_SIZE'],\n",
    "                                               num_workers=HPARAMS['NUM_WORKERS'],\n",
    "                                               sampler=train_indices\n",
    "                                                  )\n",
    "        test_loader = train_loader\n",
    "        \n",
    "    return train_loader,test_loader\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def train_recon(train_parameters,mode='train'):\n",
    "\n",
    "    result = {}\n",
    "    result['loss_recon_sum'] = 0\n",
    "    result['output']=0\n",
    "\n",
    "    if mode=='train':\n",
    "        train_parameters['model_recon'].train()\n",
    "        # train_parameters['model_recon'].mask_led=train_parameters['model_recon'].mask_led.to(DEVICE)\n",
    "        \n",
    "        for i, (data, target, cropR) in enumerate(train_parameters['trainset_loader']):\n",
    "\n",
    "            data, target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "\n",
    "            train_parameters['optimizer_recon'].zero_grad()\n",
    "            output_recon = train_parameters['model_recon'](data)\n",
    "\n",
    "            loss_phase = train_parameters['loss_function'].forward(output_recon[:,0,:,:], target[:,3,:,:],'l1')\n",
    "            loss_amp = train_parameters['loss_function'].forward(output_recon[:,1,:,:], target[:,4,:,:],'l1')\n",
    "\n",
    "            \n",
    "            loss_recon = loss_phase #+ loss_amp\n",
    "            if train_parameters['WEIGHT_FORWARD']>0:\n",
    "                output_raw_crop = TPARAMS['model_forward_crop'].forward(output_recon[:,0,:,:],output_recon[:,1,:,:],cropR,TPARAMS['low_pass_filt'])\n",
    "                output_raw = TPARAMS['model_forward'].forward(torch.abs(output_raw_crop).to(DEVICE))\n",
    "                loss_forward = train_parameters['loss_function'].forward(output_raw, data,'l1')\n",
    "                loss_recon = loss_recon + train_parameters['WEIGHT_FORWARD']*loss_forward\n",
    "            loss_recon.backward(retain_graph=True)\n",
    "            train_parameters['optimizer_recon'].step()\n",
    "\n",
    "            result['loss_recon_sum']  += loss_recon.item()\n",
    "            # train_parameters['model_recon'].led_weights=torch.clamp(train_parameters['model_recon'].led_weights,min=0.0,max=1.0)\n",
    "            torch.clamp(train_parameters['model_recon'].led_weights,min=0.0,max=1.0)\n",
    "\n",
    "            \n",
    "    elif mode =='test':\n",
    "        train_parameters['model_recon'].eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target, cropR) in enumerate(train_parameters['validset_loader']):\n",
    "                data,target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "\n",
    "                output_recon = train_parameters['model_recon'](data)\n",
    "                loss_phase = train_parameters['loss_function'].forward(output_recon[:,0,:,:], target[:,3,:,:],'l1')\n",
    "\n",
    "                loss_recon = loss_phase\n",
    "                if train_parameters['WEIGHT_FORWARD']>0:\n",
    "                    output_raw_crop = TPARAMS['model_forward_crop'].forward(output_recon[:,0,:,:],output_recon[:,1,:,:],cropR,TPARAMS['low_pass_filt'])\n",
    "                    output_raw = TPARAMS['model_forward'].forward(torch.abs(output_raw_crop).to(DEVICE))\n",
    "                    loss_forward = train_parameters['loss_function'].forward(output_raw, data,'l1')\n",
    "                    loss_recon = loss_recon + train_parameters['WEIGHT_FORWARD']*loss_forward\n",
    "\n",
    "                result['loss_recon_sum']  += loss_recon.item()\n",
    "    \n",
    "    result['LED_Power'] = led_visualize(TPARAMS)\n",
    "    result['output_phase']=output_recon[:,0,:,:].view(-1,1,600,600)    \n",
    "    result['output_amp']=output_recon[:,1,:,:].view(-1,1,600,600)\n",
    "    result['label_phase']=(target[:,3,:,:]).view(-1,1,600,600)\n",
    "    result['label_amp']=target[:,4,:,:].view(-1,1,600,600)\n",
    "    result['input_BF']=data[:, 96, :, :].view(-1,1,200,200)\n",
    "    # result['input_BF_estimated']=output_raw[:, 96, :, :].view(-1,1,200,200)\n",
    "    result['input_DF']=data[:, 100, :, :].view(-1,1,200,200)\n",
    "    # result['input_DF_estimated']=output_raw[:, 100, :, :].view(-1,1,200,200)\n",
    "    return result        \n",
    "    \n",
    "def train_stain(train_parameters):\n",
    "    train_parameters['model_stain'].train()\n",
    "    result = {}\n",
    "    result['loss_stain_sum']=0\n",
    "    result['loss_sum']=0\n",
    "    result['loss_tv_sum']=0\n",
    "    result['loss_fake_valid_sum']=0\n",
    "    \n",
    "    for i, (item1, item2) in enumerate(zip(train_parameters['trainset_loader'],train_parameters['validset_loader'])):\n",
    "\n",
    "        target = item1\n",
    "        target_valid = item2\n",
    "        \n",
    "        target = target.to(DEVICE)\n",
    "        target_valid = target_valid.to(DEVICE)\n",
    "        \n",
    "        train_parameters['optimizer_stain'].zero_grad()\n",
    "        \n",
    "        output_stain = train_parameters['model_stain'](target[:,3,:,:].view(-1,1,600,600))\n",
    "        \n",
    "\n",
    "        phase_matched = match_histograms(target[:,3,:,:].view(-1,1,600,600).squeeze(1).cpu().numpy(), target_valid[:,3,:,:].view(-1,1,600,600).squeeze(1).cpu().numpy(),channel_axis=0)\n",
    "        phase_matched=torch.from_numpy(phase_matched).unsqueeze(1).to(DEVICE)\n",
    "        output_stain_valid = train_parameters['model_stain'](phase_matched)\n",
    "        \n",
    "        \n",
    "        \n",
    "        output_fake_valid=train_parameters['model_disc_valid'](output_stain_valid)\n",
    "        \n",
    "#         \n",
    "        loss_stain = train_parameters['loss_function'].forward(output_stain, target[:,0:3,:,:],'l1')\n",
    "        loss_fake_valid=((1-output_fake_valid)**2).mean()\n",
    "        loss_tv=tv_iso2d(output_stain)\n",
    "                \n",
    "        loss=loss_stain\n",
    "        \n",
    "        if train_parameters['WEIGHT_DISC']>0:\n",
    "            loss=loss+train_parameters['WEIGHT_DISC']*loss_fake_valid\n",
    "        elif train_parameters['WEIGHT_TV']>0:\n",
    "            loss=loss+train_parameters['WEIGHT_TV']*loss_tv\n",
    "            \n",
    "        loss.backward()\n",
    "        train_parameters['optimizer_stain'].step()\n",
    "        \n",
    "        result['loss_sum']  += loss.item()\n",
    "        result['loss_stain_sum']  += loss_stain.item()\n",
    "        result['loss_tv_sum']+= loss_tv.item()\n",
    "        result['loss_fake_valid_sum']+= loss_fake_valid.item()\n",
    "    \n",
    "    train_parameters['model_stain'].eval()\n",
    "    output_stain_valid_ref = train_parameters['model_stain'](target_valid[:,3,:,:].view(-1,1,600,600))\n",
    "    \n",
    "\n",
    "    result['label_phase']=(target[:,3,:,:]).view(-1,1,600,600)\n",
    "    result['label_stain']=target[:,0:3,:,:].view(-1,3,600,600)\n",
    "    result['output_stain']=output_stain.view(-1,3,600,600)\n",
    "    result['output_phase_hm']=phase_matched.view(-1,1,600,600)\n",
    "    \n",
    "    result['label_phase_unstained']=(target_valid[:,3,:,:]).view(-1,1,600,600)\n",
    "    result['label_stain_unstained']=target_valid[:,0:3,:,:].view(-1,3,600,600)\n",
    "    result['output_stain_hm']=output_stain_valid.view(-1,3,600,600)\n",
    "    result['output_stain_unstained']=output_stain_valid_ref.view(-1,3,600,600)\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_disc(train_parameters):\n",
    "\n",
    "    train_parameters['model_disc_valid'].train()\n",
    "    result = {}\n",
    "    result['loss_disc_valid_sum']=0\n",
    "    \n",
    "\n",
    "    for i, (item1, item2) in enumerate(zip(train_parameters['trainset_loader'],train_parameters['validset_loader'])):\n",
    "\n",
    "        data, target, cropR = item1\n",
    "        data_valid, target_valid, cropR_valid = item2\n",
    "        \n",
    "        target = target.to(DEVICE)\n",
    "        target_valid = target_valid.to(DEVICE)\n",
    "        \n",
    "\n",
    "        train_parameters['optimizer_disc_valid'].zero_grad()\n",
    "        \n",
    "        # output_stain = train_parameters['model_stain'](target[:,3,:,:].view(-1,1,600,600))   \n",
    "        phase_matched = match_histograms(target[:,3,:,:].view(-1,1,600,600).squeeze(1).cpu().numpy(), target_valid[:,3,:,:].view(-1,1,600,600).squeeze(1).cpu().numpy(),channel_axis=0)\n",
    "        output_stain_valid = train_parameters['model_stain'](torch.from_numpy(phase_matched).unsqueeze(1).to(DEVICE))\n",
    "        # output_stain_valid = train_parameters['model_stain'](target_valid[:,3,:,:].view(-1,1,600,600))\n",
    "       \n",
    "        \n",
    "        output_fake_valid=train_parameters['model_disc_valid'](output_stain_valid)\n",
    "        # output_real_valid=train_parameters['model_disc_valid'](output_stain)\n",
    "        output_real_valid=train_parameters['model_disc_valid'](target[:,0:3,:,:])\n",
    "                \n",
    "        ra=(output_fake_valid**2+(1-output_real_valid)**2).mean()\n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "        [output_fake_valid,df1,df2,df3,df4]=train_parameters['model_disc_valid'](output_stain_valid)\n",
    "        # output_real_valid=train_parameters['model_disc_valid'](output_stain)\n",
    "        [output_real_valid,dr1,dr2,dr3,dr4]=train_parameters['model_disc_valid'](target[:,0:3,:,:])\n",
    "        lam_p1 = 5.\n",
    "        lam_p2 = 1.5\n",
    "        lam_p3 = 1.5\n",
    "        lam_p4 = 1.\n",
    "        m=3.0\n",
    "        p1 = lam_p1*train_parameters['loss_function'].forward(df1, dr1,'l1')\n",
    "        p2 = lam_p2*train_parameters['loss_function'].forward(df2, dr2,'l1')\n",
    "        p3 = lam_p3*train_parameters['loss_function'].forward(df3, dr3,'l1')\n",
    "        p4 = lam_p4*train_parameters['loss_function'].forward(df4, dr4,'l1')\n",
    "        \n",
    "        l1_perception = p1 + p2 + p3 + p4\n",
    "\n",
    "        loss_disc_valid=(output_fake_valid**2+(1-output_real_valid)**2).mean()\n",
    "        loss_disc_valid=loss_disc_valid+(m-l1_perception)\n",
    "        ############################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_disc_valid.backward()\n",
    "        train_parameters['optimizer_disc_valid'].step()\n",
    "\n",
    "        result['loss_disc_valid_sum']  += loss_disc_valid.item()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def train_disc_recon(train_parameters):\n",
    "\n",
    "    train_parameters['model_disc_valid'].train()\n",
    "    result = {}\n",
    "    result['loss_disc_valid_sum']=0\n",
    "    result['loss_perception_sum']=0\n",
    "    \n",
    "\n",
    "    for i, (item1, item2) in enumerate(zip(train_parameters['trainset_loader'],train_parameters['validset_loader'])):\n",
    "\n",
    "        data, target, cropR = item1\n",
    "        data_valid, target_valid, cropR_valid = item2\n",
    "        \n",
    "        \n",
    "        data,target, cropR = item1\n",
    "        data_valid, target_valid, cropR_valid = item2\n",
    "\n",
    "        data, target, cropR=data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "        data_valid, target_valid, cropR_valid=data_valid.to(DEVICE),target_valid.to(DEVICE),cropR_valid.to(DEVICE)\n",
    "        \n",
    "\n",
    "        train_parameters['optimizer_disc_valid'].zero_grad()\n",
    "        \n",
    "        output_recon = train_parameters['model_recon'](data)\n",
    "        output_recon_valid = train_parameters['model_recon'](data_valid)\n",
    "\n",
    "\n",
    "\n",
    "        output_real_valid,dr1,dr2,dr3,dr4=train_parameters['model_disc_valid'](output_recon[:,0,:,:].unsqueeze(1))\n",
    "        output_fake_valid,df1,df2,df3,df4=train_parameters['model_disc_valid'](output_recon_valid[:,0,:,:].unsqueeze(1))\n",
    "        lam_p1 = 3.\n",
    "        lam_p2 = 1.5\n",
    "        lam_p3 = 1.5\n",
    "        lam_p4 = 1.\n",
    "        p1 = lam_p1*train_parameters['loss_function'].forward(df1, dr1,'l1')\n",
    "        p2 = lam_p2*train_parameters['loss_function'].forward(df2, dr2,'l1')\n",
    "        p3 = lam_p3*train_parameters['loss_function'].forward(df3, dr3,'l1')\n",
    "        p4 = lam_p4*train_parameters['loss_function'].forward(df4, dr4,'l1')\n",
    "\n",
    "\n",
    "\n",
    "        l1_perception = p1 + p2 + p3 + p4\n",
    "        m=3.0\n",
    "\n",
    "\n",
    "        loss_disc_valid=(output_fake_valid**2+(1-output_real_valid)**2).mean()\n",
    "        loss=loss_disc_valid+(m-l1_perception)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        train_parameters['optimizer_disc_valid'].step()\n",
    "\n",
    "        result['loss_disc_valid_sum']  += loss_disc_valid.item()\n",
    "        result['loss_perception_sum']  += (m-l1_perception).item()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def train_raw_to_stain(train_parameters,epoch,mode='train'):\n",
    "    result = {}\n",
    "    result['loss_stain_sum']=0\n",
    "    result['loss_sum']=0\n",
    "    result['loss_tv_sum']=0\n",
    "    result['loss_recon_sum'] = 0\n",
    "    result['loss_disc_valid_sum']=0\n",
    "\n",
    "    \n",
    "    if mode=='train':\n",
    "        # train_parameters['model_recon'].train()\n",
    "        train_parameters['model_stain'].train()\n",
    "        train_parameters['model_contrastive'].train()\n",
    "        \n",
    "    \n",
    "   \n",
    "        \n",
    "        for i, (item1, item2) in enumerate(zip(train_parameters['trainset_loader'],train_parameters['validset_loader'])):\n",
    "\n",
    "            data,target, cropR = item1\n",
    "            data_valid, target_valid, cropR_valid = item2\n",
    "            \n",
    "            data, target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "            data_valid, target_valid, cropR_valid=data_valid.to(DEVICE),target_valid.to(DEVICE),cropR_valid.to(DEVICE)\n",
    "           \n",
    " \n",
    "            \n",
    "            output_recon= train_parameters['model_recon'](data)\n",
    "            output_recon_valid = train_parameters['model_recon'](data_valid)\n",
    "            loss_phase = train_parameters['loss_function'].forward(output_recon[:,0,:,:], target[:,3,:,:],'l1')\n",
    "            \n",
    "            loss_recon = loss_phase\n",
    "            \n",
    "            \n",
    "                    \n",
    "            ### train stain w contrastive ###\n",
    "            output_stain, f1 = train_parameters['model_stain'](output_recon[:,0,:,:].view(-1,1,600,600))\n",
    "            f1=train_parameters['model_contrastive'](f1)\n",
    "            \n",
    "            output_stain_valid, f2 = train_parameters['model_stain'](output_recon_valid[:,0,:,:].view(-1,1,600,600))\n",
    "            f2=train_parameters['model_contrastive'](f2)\n",
    "\n",
    "\n",
    "            loss_contrastive = train_parameters['loss_function'].forward(f1.unsqueeze(1), f2.unsqueeze(1),'l1')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            loss_stain = train_parameters['loss_function'].forward(output_stain, target[:,0:3,:,:],'mse')\n",
    "            loss=loss_stain * train_parameters['WEIGHT_STAIN']\n",
    "\n",
    "            if train_parameters['WEIGHT_DISC']>0:\n",
    "                loss=loss+train_parameters['WEIGHT_DISC']*loss_contrastive\n",
    "\n",
    "\n",
    "            train_parameters['optimizer_entire'].zero_grad()\n",
    "            # loss_recon.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            train_parameters['optimizer_entire'].step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            result['loss_recon_sum']  += loss_phase.item()\n",
    "            result['loss_stain_sum']  += loss_stain.item()\n",
    "            result['loss_disc_valid_sum'] += loss_contrastive.item()\n",
    "\n",
    "            \n",
    "            \n",
    "            # train_parameters['model_recon'].led_weights.clamp(min=0.0,max=1.0)\n",
    "\n",
    "            \n",
    "    elif mode =='test':\n",
    "        train_parameters['model_recon'].eval()\n",
    "        train_parameters['model_stain'].eval()\n",
    "        # train_parameters['model_disc_valid'].eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # for i, (data, target, cropR) in enumerate(train_parameters['validset_loader']):\n",
    "            \n",
    "            (data, target, cropR) =next(iter(train_parameters['validset_loader']))\n",
    "            data,target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "\n",
    "            output_recon  = train_parameters['model_recon'](data)\n",
    "            loss_phase = train_parameters['loss_function'].forward(output_recon[:,0,:,:], target[:,3,:,:],'mse')\n",
    "            loss_recon = loss_phase\n",
    "\n",
    "\n",
    "            \n",
    "            # output_stain,feats = train_parameters['model_stain'](target[:,3,:,:].view(-1,1,600,600))\n",
    "            output_stain,feats = train_parameters['model_stain'](output_recon[:,0,:,:].view(-1,1,600,600))\n",
    "            loss_stain = train_parameters['loss_function'].forward(output_stain[:,0,:,:], target[:,0,:,:],'mse')\n",
    "            loss_tv=tv_iso2d(output_stain)\n",
    "\n",
    "\n",
    "            if train_parameters['WEIGHT_TV']>0:\n",
    "                loss=loss+train_parameters['WEIGHT_TV']*loss_tv\n",
    "\n",
    "            result['loss_recon_sum']  += loss_recon.item()\n",
    "            result['loss_stain_sum']  += loss_stain.item()\n",
    "                \n",
    "\n",
    "    result['LED_Power'] = led_visualize(train_parameters)\n",
    "    result['output_phase']=output_recon[:,0,:,:].view(-1,1,600,600)    \n",
    "    # result['output_phase']=target[:,3,:,:].view(-1,1,600,600)    \n",
    "    # result['output_amp']=target[:,4,:,:].view(-1,1,600,600)\n",
    "    result['output_amp']=output_recon[:,1,:,:].view(-1,1,600,600)\n",
    "    result['label_phase']=(target[:,3,:,:]).view(-1,1,600,600)\n",
    "    result['label_amp']=target[:,4,:,:].view(-1,1,600,600)\n",
    "    result['input_BF']=data[:, 96, :, :].view(-1,1,200,200)\n",
    "    result['input_DF']=data[:, 100, :, :].view(-1,1,200,200)\n",
    "    result['label_stain']=target[:,0:3,:,:].view(-1,3,600,600)\n",
    "    result['output_stain']=output_stain.view(-1,3,600,600)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def train_end2end(train_parameters,epoch,mode='train'):\n",
    "    result = {}\n",
    "    result['loss_stain_sum']=0\n",
    "    result['loss_sum']=0\n",
    "    result['loss_tv_sum']=0\n",
    "    result['loss_recon_sum'] = 0\n",
    "    result['loss_disc_valid_sum']=0\n",
    "\n",
    "    \n",
    "    if mode=='train':\n",
    "        train_parameters['model_recon'].train()\n",
    "    \n",
    "        for i, (item1, item2) in enumerate(zip(train_parameters['trainset_loader'],train_parameters['validset_loader'])):\n",
    "\n",
    "            data,target, cropR = item1\n",
    "            data, target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "        \n",
    "            output_stain = train_parameters['model_recon'](data)\n",
    "            loss_stain = train_parameters['loss_function'].forward(output_stain, target[:,0:3,:,:],'l1')\n",
    "            \n",
    "            loss = loss_stain * train_parameters['WEIGHT_STAIN']\n",
    "\n",
    "            train_parameters['optimizer_stain'].zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            train_parameters['optimizer_stain'].step()\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            result['loss_stain_sum']  += loss_stain.item()\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    elif mode =='test':\n",
    "        train_parameters['model_recon'].eval()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # for i, (data, target, cropR) in enumerate(train_parameters['validset_loader']):\n",
    "            \n",
    "            (data, target, cropR) =next(iter(train_parameters['validset_loader']))\n",
    "            data,target, cropR = data.to(DEVICE),target.to(DEVICE),cropR.to(DEVICE)\n",
    "\n",
    "            output_stain = train_parameters['model_recon'](data)\n",
    "            loss_stain = train_parameters['loss_function'].forward(output_stain, target[:,0:3,:,:],'l1')\n",
    "\n",
    "            result['loss_stain_sum']  += loss_stain.item()\n",
    "                \n",
    "\n",
    "    result['LED_Power'] = led_visualize(train_parameters)\n",
    "    result['output_phase']=output_stain[:,0,:,:].view(-1,1,600,600)    \n",
    "    # result['output_phase']=target[:,3,:,:].view(-1,1,600,600)    \n",
    "    # result['output_amp']=target[:,4,:,:].view(-1,1,600,600)\n",
    "    result['output_amp']=output_stain[:,1,:,:].view(-1,1,600,600)\n",
    "    result['label_phase']=(target[:,3,:,:]).view(-1,1,600,600)\n",
    "    result['label_amp']=target[:,4,:,:].view(-1,1,600,600)\n",
    "    result['input_BF']=data[:, 96, :, :].view(-1,1,200,200)\n",
    "    result['input_DF']=data[:, 100, :, :].view(-1,1,200,200)\n",
    "    result['label_stain']=target[:,0:3,:,:].view(-1,3,600,600)\n",
    "    result['output_stain']=output_stain.view(-1,3,600,600)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def main(TPARAMS):\n",
    "    \"\"\"Main process function.\"\"\"\n",
    "    \n",
    "    \n",
    "    ## Load Dataset\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    TPARAMS['loss_function'] = LossFunction()\n",
    "    \n",
    "    # Initialize model\n",
    "    if HPARAMS['TRAIN_MODE']=='RECON':\n",
    "        TPARAMS['model_recon'] = models.RCAN_recon(IMAGE_SHAPE_INTER).to(DEVICE)\n",
    "        TPARAMS['model_forward'] = models.Post_Pupil_Net().to(DEVICE) \n",
    "        TPARAMS['model_forward_crop'] = models.Forward_Crop().to(DEVICE) \n",
    "        TPARAMS['model_forward'].load_state_dict(torch.load(save_weight_dir+'forward/'+name_weight_forward+'.pth'))\n",
    "        TPARAMS['low_pass_filt']=models.generate_transfer_function().to(DEVICE) \n",
    "\n",
    "        \n",
    "        TPARAMS['led_list']=TPARAMS['model_recon'].led_list\n",
    "        TPARAMS['model_recon'].mask_led=TPARAMS['model_recon'].mask_led.to(DEVICE)\n",
    "        \n",
    "        TPARAMS['optimizer_recon'] = optim.Adam([{\"params\": TPARAMS['model_recon'].led_weights, \"lr\": HPARAMS['LR']*1e1},{\"params\": TPARAMS['model_recon'].head.parameters()},{\"params\": TPARAMS['model_recon'].body.parameters()},{\"params\": TPARAMS['model_recon'].tail.parameters()}],lr=HPARAMS['LR'] )\n",
    "\n",
    "        wandb.watch(TPARAMS['model_recon'], criterion=TPARAMS['loss_function'], log='all')\n",
    "        \n",
    "        dataset = FPM_recon_dataset_RED(root=images_raw,\n",
    "                                                  transform=transformer)\n",
    "        dataset_valid = FPM_recon_dataset_RED(root=images_raw_valid,\n",
    "                                                  transform=transformer)\n",
    "        \n",
    "\n",
    "\n",
    "    if HPARAMS['TRAIN_MODE']=='STAIN':\n",
    "        TPARAMS['model_stain'] = models.UNet(IMAGE_SHAPE_INTER).to(DEVICE)\n",
    "        TPARAMS['model_disc_valid'] = discriminator.Discriminator().to(DEVICE)\n",
    "        # TPARAMS['model_disc_valid'] = Attention_GAN.Discriminator().to(DEVICE)\n",
    "        \n",
    "        \n",
    "        TPARAMS['optimizer_stain'] = optim.Adam(TPARAMS['model_stain'].parameters(), lr=HPARAMS['LR'])\n",
    "        TPARAMS['optimizer_disc_valid'] = optim.Adam(TPARAMS['model_disc_valid'].parameters(), lr=HPARAMS['LR_DISC'])\n",
    "        wandb.watch(TPARAMS['model_stain'], criterion=TPARAMS['loss_function'], log='all')\n",
    "        wandb.watch(TPARAMS['model_disc_valid'], criterion=TPARAMS['loss_function'], log='all')\n",
    "        \n",
    "        dataset = FPM_dataset_RED(root=images_raw,\n",
    "                                                  transform=transformer)\n",
    "        dataset_valid = FPM_dataset_RED(root=images_raw_valid,\n",
    "                                                  transform=transformer)\n",
    "                \n",
    "    if HPARAMS['TRAIN_MODE']=='END2END': \n",
    "        TPARAMS['model_recon'] = models.RCAN_stain(IMAGE_SHAPE_INTER, TPARAMS['NUM_BF'], TPARAMS['NUM_DF']).to(DEVICE)\n",
    "        \n",
    "        \n",
    "        TPARAMS['led_list']=TPARAMS['model_recon'].led_list\n",
    "        TPARAMS['model_recon'].mask_led=TPARAMS['model_recon'].mask_led.to(DEVICE)\n",
    "        \n",
    "        TPARAMS['optimizer_stain'] = optim.Adam([{\"params\": TPARAMS['model_recon'].led_weights, \"lr\": LR_LED},\n",
    "                                                  {\"params\": TPARAMS['model_recon'].head.parameters(), \"lr\": LR_HEAD},\n",
    "                                                  {\"params\": TPARAMS['model_recon'].body.parameters(), \"lr\": LR_BODY},\n",
    "                                                  {\"params\": TPARAMS['model_recon'].tail.parameters(), \"lr\": LR_TAIL}, ##1e+1\n",
    "                                                  ],lr=HPARAMS['LR'] )\n",
    "\n",
    "        \n",
    "        dataset = FPM_recon_dataset_RED(root=images_raw,\n",
    "                                                  transform=transformer)\n",
    "        dataset_valid = FPM_recon_dataset_RED(root=images_raw_valid,\n",
    "                                                  transform=transformer)\n",
    "    \n",
    "        \n",
    "        \n",
    "    if HPARAMS['TRAIN_MODE']=='ENTIRE':\n",
    "        TPARAMS['contrastive_loss'] = SupConLoss(DEVICE, temperature=0.07, contrast_mode='one').to(DEVICE) \n",
    "        TPARAMS['model_recon'] = models.RCAN_recon(IMAGE_SHAPE_INTER, TPARAMS['NUM_BF'], TPARAMS['NUM_DF']).to(DEVICE)\n",
    "        # TPARAMS['model_recon'].load_state_dict(torch.load(save_weight_dir+'recon/'+name_weight_recon+'.pth'))\n",
    "        TPARAMS['model_recon'].load_state_dict(torch.load('/mnt/data3/KC/virtual_staining/weights/recon/'+name_weight_recon+'.pth'))\n",
    "        \n",
    "\n",
    "        \n",
    "        TPARAMS['model_stain'] = models.UNet_contrastive(IMAGE_SHAPE_INTER).to(DEVICE)\n",
    "        TPARAMS['model_contrastive'] = models.MLP_contrastive(IMAGE_SHAPE_INTER, TPARAMS['FEAT_DIM']).to(DEVICE)\n",
    "\n",
    "        \n",
    "        TPARAMS['led_list']=TPARAMS['model_recon'].led_list\n",
    "        TPARAMS['model_recon'].mask_led=TPARAMS['model_recon'].mask_led.to(DEVICE)\n",
    "\n",
    "        \n",
    "        TPARAMS['optimizer_entire'] = optim.Adam([\n",
    "                                                  {\"params\": TPARAMS['model_contrastive'].parameters(), \"lr\": LR_CONTRASTIVE},\n",
    "                                                  {\"params\": TPARAMS['model_stain'].parameters()}],lr=HPARAMS['LR'] )\n",
    "        \n",
    "\n",
    "                \n",
    "        dataset = FPM_recon_dataset_RED(root=images_raw,\n",
    "                                                  transform=transformer)\n",
    "        dataset_valid = FPM_recon_dataset_RED(root=images_raw_valid,\n",
    "                                                  transform=transformer)\n",
    "        \n",
    "    TPARAMS['trainset_loader'],TPARAMS['testset_loader']=data_sampler(dataset,train_size=HPARAMS['TRAIN_SIZE'],test_size=HPARAMS['TEST_SIZE'],mode=HPARAMS['MODE'])\n",
    "    _,TPARAMS['validset_loader']=data_sampler(dataset_valid,train_size=0,test_size=HPARAMS['VALID_SIZE'],mode=HPARAMS['MODE'])    \n",
    "    \n",
    "\n",
    "    ##############################################################\n",
    "    w=-1\n",
    "    nSubEpoch=50\n",
    "    if HPARAMS['MODE'] =='train':\n",
    "        print('Train Start!')\n",
    "\n",
    "        \n",
    "        \n",
    "        for epoch in range(HPARAMS['EPOCHS_NUM']):\n",
    "            start_time = time.time()\n",
    "            TPARAMS['epoch_now'] = epoch\n",
    "\n",
    "            if HPARAMS['TRAIN_MODE']=='RECON':\n",
    "                train_result_recon = train_recon(TPARAMS,'train')\n",
    "                wandb.log({\"Train Total Recon Loss\": train_result_recon['loss_recon_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)    \n",
    "                test_result_recon = train_recon(TPARAMS,'test')\n",
    "                wandb.log({\"Test Total Recon Loss\": test_result_recon['loss_recon_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)    \n",
    "                plot_train_recon(train_result_recon, epoch,'train')\n",
    "                plot_train_recon(test_result_recon, epoch,'test')\n",
    "\n",
    "                \n",
    "            if HPARAMS['TRAIN_MODE']=='ENTIRE':\n",
    "                wandb.watch(TPARAMS['model_recon'], criterion=TPARAMS['loss_function'], log='all')\n",
    "                wandb.watch(TPARAMS['model_stain'], criterion=TPARAMS['loss_function'], log='all')\n",
    "                wandb.watch(TPARAMS['model_contrastive'], criterion=TPARAMS['loss_function'], log='all')\n",
    "                train_result_entire = train_raw_to_stain(TPARAMS,epoch,'train')\n",
    "                test_result_entire = train_raw_to_stain(TPARAMS,epoch,'test')\n",
    "                wandb.log({\"Train Total Recon Loss\": train_result_entire['loss_recon_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)                    \n",
    "                wandb.log({\"Test Total Recon Loss\": test_result_entire['loss_recon_sum']/ len(TPARAMS['validset_loader'])}, step=epoch)    \n",
    "                wandb.log({\"Train Stain Loss\": train_result_entire['loss_stain_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)\n",
    "                wandb.log({\"Test Stain Loss\": test_result_entire['loss_stain_sum']/ len(TPARAMS['validset_loader'])}, step=epoch)\n",
    "                wandb.log({\"Train Disc Loss\": train_result_entire['loss_disc_valid_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)\n",
    "                if np.mod(epoch,10) == 0 or epoch == HPARAMS['EPOCHS_NUM']:\n",
    "                    plot_train_entire(train_result_entire, epoch,'train')\n",
    "                    plot_train_entire(test_result_entire, epoch,'test')\n",
    "                \n",
    "            if HPARAMS['TRAIN_MODE']=='END2END':\n",
    "                wandb.watch(TPARAMS['model_recon'], criterion=TPARAMS['loss_function'], log='all')\n",
    "                train_result_entire = train_end2end(TPARAMS,epoch,'train')\n",
    "                test_result_entire = train_end2end(TPARAMS,epoch,'test')\n",
    "                wandb.log({\"Train Total Recon Loss\": train_result_entire['loss_recon_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)                    \n",
    "                wandb.log({\"Test Total Recon Loss\": test_result_entire['loss_recon_sum']/ len(TPARAMS['validset_loader'])}, step=epoch)    \n",
    "                wandb.log({\"Train Stain Loss\": train_result_entire['loss_stain_sum']/ len(TPARAMS['trainset_loader'])}, step=epoch)\n",
    "                wandb.log({\"Test Stain Loss\": test_result_entire['loss_stain_sum']/ len(TPARAMS['validset_loader'])}, step=epoch)\n",
    "\n",
    "                \n",
    "                plot_train_entire(train_result_entire, epoch,'train')\n",
    "                plot_train_entire(test_result_entire, epoch,'test')\n",
    "                \n",
    "            \n",
    "                \n",
    "            print('Train :: epoch: {}. time: {:.5}s.'.format(epoch, time.time() - start_time))\n",
    "            if np.mod(epoch,HPARAMS['SAVE_SUBITER']) == 0 or epoch == HPARAMS['EPOCHS_NUM']:\n",
    "                if HPARAMS['TRAIN_MODE']=='RECON':\n",
    "                    save_weight_name_recon = save_weight_dir+\"recon/recon_\"+\"{}\".format(START_DATE)+\"_{0:05d}.pth\".format(epoch)\n",
    "                    torch.save(TPARAMS['model_recon'].state_dict(), save_weight_name_recon)                                                      \n",
    "                    \n",
    "                if HPARAMS['TRAIN_MODE']=='ENTIRE':\n",
    "                    save_weight_name_recon = save_weight_dir+\"recon/recon_\"+\"{}\".format(START_DATE)+\"_{0:05d}.pth\".format(epoch)\n",
    "                    torch.save(TPARAMS['model_recon'].state_dict(), save_weight_name_recon)\n",
    "                    save_weight_name_stain = save_weight_dir+\"stain/stain_\"+\"{}\".format(START_DATE)+\"_{0:05d}.pth\".format(epoch)\n",
    "                    torch.save(TPARAMS['model_stain'].state_dict(), save_weight_name_stain)    \n",
    "                    \n",
    "                if HPARAMS['TRAIN_MODE']=='END2END':\n",
    "                    save_weight_name_recon = save_weight_dir+\"recon/recon_\"+\"{}\".format(START_DATE)+\"_{0:05d}.pth\".format(epoch)\n",
    "                    torch.save(TPARAMS['model_recon'].state_dict(), save_weight_name_recon)\n",
    "                    # save_weight_name_stain = save_weight_dir+\"stain/stain_\"+\"{}\".format(START_DATE)+\"_{0:05d}.pth\".format(epoch)\n",
    "                    # torch.save(TPARAMS['model_stain'].state_dict(), save_weight_name_stain)    \n",
    "         \n",
    "    if HPARAMS['MODE'] =='inference':\n",
    "        print('Inference Start!')\n",
    "        # TPARAMS['model_stain'].load_state_dict(torch.load(save_weight_dir+'stain/'+name_weight_stain+'.pth'))\n",
    "        # TPARAMS['model_disc_valid'].load_state_dict(torch.load(save_weight_dir+'disc/'+name_weight_disc+'.pth'))\n",
    "        TPARAMS['model_recon'].load_state_dict(torch.load(save_weight_dir+'recon/'+name_weight_recon+'.pth'))        \n",
    "        save_imgs(TPARAMS,save_img_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(HPARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
